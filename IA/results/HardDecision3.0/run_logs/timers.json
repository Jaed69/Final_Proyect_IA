{
    "name": "root",
    "gauges": {
        "AgentControl.Policy.Entropy.mean": {
            "value": 1.310558795928955,
            "min": 1.310558795928955,
            "max": 1.3411049842834473,
            "count": 10
        },
        "AgentControl.Policy.Entropy.sum": {
            "value": 65088.90234375,
            "min": 65088.90234375,
            "max": 73180.078125,
            "count": 10
        },
        "AgentControl.Step.mean": {
            "value": 499981.0,
            "min": 49955.0,
            "max": 499981.0,
            "count": 10
        },
        "AgentControl.Step.sum": {
            "value": 499981.0,
            "min": 49955.0,
            "max": 499981.0,
            "count": 10
        },
        "AgentControl.Policy.ExtrinsicValueEstimate.mean": {
            "value": 78.1635513305664,
            "min": 61.26209259033203,
            "max": 78.1635513305664,
            "count": 10
        },
        "AgentControl.Policy.ExtrinsicValueEstimate.sum": {
            "value": 65266.5625,
            "min": 50521.0703125,
            "max": 65266.5625,
            "count": 10
        },
        "AgentControl.Environment.EpisodeLength.mean": {
            "value": 536.978947368421,
            "min": 235.6078431372549,
            "max": 575.5483870967741,
            "count": 10
        },
        "AgentControl.Environment.EpisodeLength.sum": {
            "value": 51013.0,
            "min": 12016.0,
            "max": 53526.0,
            "count": 10
        },
        "AgentControl.Environment.CumulativeReward.mean": {
            "value": 546.7894736842105,
            "min": 190.68627450980392,
            "max": 546.7894736842105,
            "count": 10
        },
        "AgentControl.Environment.CumulativeReward.sum": {
            "value": 51945.0,
            "min": 9725.0,
            "max": 51945.0,
            "count": 10
        },
        "AgentControl.Policy.ExtrinsicReward.mean": {
            "value": 546.7894736842105,
            "min": 190.68627450980392,
            "max": 546.7894736842105,
            "count": 10
        },
        "AgentControl.Policy.ExtrinsicReward.sum": {
            "value": 51945.0,
            "min": 9725.0,
            "max": 51945.0,
            "count": 10
        },
        "AgentControl.Losses.PolicyLoss.mean": {
            "value": 0.023043368878522114,
            "min": 0.020318635194402922,
            "max": 0.025188698769294814,
            "count": 10
        },
        "AgentControl.Losses.PolicyLoss.sum": {
            "value": 0.09217347551408846,
            "min": 0.06620534296153993,
            "max": 0.12594349384647407,
            "count": 10
        },
        "AgentControl.Losses.ValueLoss.mean": {
            "value": 71.53326578140259,
            "min": 63.51156100343775,
            "max": 86.01113627751668,
            "count": 10
        },
        "AgentControl.Losses.ValueLoss.sum": {
            "value": 286.13306312561036,
            "min": 190.53468301031324,
            "max": 420.34791089571434,
            "count": 10
        },
        "AgentControl.Policy.LearningRate.mean": {
            "value": 1.5384544871850005e-05,
            "min": 1.5384544871850005e-05,
            "max": 0.0002817506060831334,
            "count": 10
        },
        "AgentControl.Policy.LearningRate.sum": {
            "value": 6.153817948740002e-05,
            "min": 6.153817948740002e-05,
            "max": 0.0012683958772013997,
            "count": 10
        },
        "AgentControl.Policy.Epsilon.mean": {
            "value": 0.10512815000000003,
            "min": 0.10512815000000003,
            "max": 0.19391686666666672,
            "count": 10
        },
        "AgentControl.Policy.Epsilon.sum": {
            "value": 0.4205126000000001,
            "min": 0.4205126000000001,
            "max": 0.9227986000000001,
            "count": 10
        },
        "AgentControl.Policy.Beta.mean": {
            "value": 0.00026589468500000005,
            "min": 0.00026589468500000005,
            "max": 0.004696451646666666,
            "count": 10
        },
        "AgentControl.Policy.Beta.sum": {
            "value": 0.0010635787400000002,
            "min": 0.0010635787400000002,
            "max": 0.021147650139999995,
            "count": 10
        },
        "AgentControl.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "AgentControl.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1732367271",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\penca\\.conda\\envs\\mlagents\\Scripts\\mlagents-learn C:/Users/penca/Desktop/Final_Proyect_IA/IA/results/HardDecision3.0/configuration.yaml --run-id=HardDecision3.0 --force",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.5.0+cpu",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1732367615"
    },
    "total": 344.1127510999795,
    "count": 1,
    "self": 0.009397299960255623,
    "children": {
        "run_training.setup": {
            "total": 0.0668081000330858,
            "count": 1,
            "self": 0.0668081000330858
        },
        "TrainerController.start_learning": {
            "total": 344.03654569998616,
            "count": 1,
            "self": 0.15723490196978673,
            "children": {
                "TrainerController._reset_env": {
                    "total": 10.847038200008683,
                    "count": 1,
                    "self": 10.847038200008683
                },
                "TrainerController.advance": {
                    "total": 332.9538453979767,
                    "count": 4580,
                    "self": 0.16898709669476375,
                    "children": {
                        "env_step": {
                            "total": 178.75907590141287,
                            "count": 4580,
                            "self": 161.65749300655443,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 17.022836196236312,
                                    "count": 4580,
                                    "self": 0.6378702986403368,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 16.384965897595976,
                                            "count": 3906,
                                            "self": 16.384965897595976
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.07874669862212613,
                                    "count": 4580,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 334.3441831006785,
                                            "count": 4580,
                                            "is_parallel": true,
                                            "self": 201.48889410030097,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0019733000081032515,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00040010001976042986,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0015731999883428216,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0015731999883428216
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 132.85331570036942,
                                                    "count": 4580,
                                                    "is_parallel": true,
                                                    "self": 3.444899903028272,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 6.828504601842724,
                                                            "count": 4580,
                                                            "is_parallel": true,
                                                            "self": 6.828504601842724
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 114.15931819798425,
                                                            "count": 4580,
                                                            "is_parallel": true,
                                                            "self": 114.15931819798425
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 8.420592997514177,
                                                            "count": 4580,
                                                            "is_parallel": true,
                                                            "self": 1.6150827942183241,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 6.805510203295853,
                                                                    "count": 18320,
                                                                    "is_parallel": true,
                                                                    "self": 6.805510203295853
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 154.02578239986906,
                            "count": 4580,
                            "self": 0.38802469678921625,
                            "children": {
                                "process_trajectory": {
                                    "total": 46.36664080288028,
                                    "count": 4580,
                                    "self": 45.68930630275281,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.677334500127472,
                                            "count": 10,
                                            "self": 0.677334500127472
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 107.27111690019956,
                                    "count": 46,
                                    "self": 74.7965095009422,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 32.474607399257366,
                                            "count": 1422,
                                            "self": 32.474607399257366
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.100008375942707e-06,
                    "count": 1,
                    "self": 1.100008375942707e-06
                },
                "TrainerController._save_models": {
                    "total": 0.07842610002262518,
                    "count": 1,
                    "self": 0.008962700027041137,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.06946339999558404,
                            "count": 1,
                            "self": 0.06946339999558404
                        }
                    }
                }
            }
        }
    }
}